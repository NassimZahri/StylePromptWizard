[PROBLEMATIQUE]

Dans un contexte où l’image est devenue un langage universel, la capacité à comprendre, décrire et reproduire un visuel de manière rapide et précise représente un avantage compétitif considérable. Les créateurs de contenu, les agences publicitaires et les entreprises cherchent de plus en plus à exploiter les technologies d’intelligence artificielle pour optimiser leurs processus créatifs. Le projet présenté dans ce rapport répond directement à ce besoin en proposant une application innovante qui génère automatiquement, à partir d’une image, un prompt textuel détaillé et structuré décrivant le contexte visuel de l'image donnée.

L’utilité de cette application se révèle à travers différents scénarios concrets. Un créateur de contenu peut l’utiliser pour analyser ses propres visuels et en extraire une description riche, utile pour améliorer le référencement, adapter le contenu à divers publics ou enrichir des publications sur les réseaux sociaux. Dans un autre contexte, une entreprise chinoise souhaitant reproduire le style d’un poster ou d’une publicité existante pourrait s’appuyer sur l’application pour obtenir une analyse descriptive précise de l’image. Ce prompt servirait alors de point de départ à la création d’un nouveau visuel respectant le style original, mais appliqué à son propre produit, permettant ainsi un gain de temps et une meilleure cohérence graphique.

Derrière cette utilité se cache une architecture technique moderne et robuste. L’application est développée en Python, en s’appuyant sur un framework web performant comme FastAPI ou Flask, ce qui permet d’offrir une API REST capable de traiter des images et de générer des prompts à l’aide d’un modèle d’IA générative. L’IA peut être basée sur Azure Cognitive Services ou un modèle d’apprentissage machine personnalisé, garantissant une description fidèle et pertinente.

Afin d’assurer la portabilité et la cohérence entre les environnements, l’application est encapsulée dans un conteneur Docker optimisé grâce à une construction multi-étapes. Ce conteneur est ensuite stocké dans Azure Container Registry et déployé sur Azure Container Apps, bénéficiant ainsi d’une mise à l’échelle automatique et d’une disponibilité élevée. La sécurité est également au cœur du projet, avec une gestion centralisée et sécurisée des clés et secrets via Azure Key Vault.

L’approche DevOps adoptée assure un cycle de vie logiciel fluide et automatisé. Grâce à GitHub Actions, un pipeline CI/CD multi-environnements (staging et production) est mis en place, intégrant les étapes de compilation, de tests, de déploiement et de validation manuelle. Le suivi de la performance et la détection des incidents sont assurés par Azure Monitor et Log Analytics, qui collectent les métriques et déclenchent des alertes en cas d’anomalie. Par ailleurs, des outils d’automatisation comme n8n ou Power Automate notifient les équipes lors des déploiements ou des erreurs critiques, garantissant une réactivité optimale.

Enfin, la totalité de l’infrastructure cloud est déployée et gérée via une approche Infrastructure as Code, en utilisant Bicep ou Terraform. Cette méthode permet de reproduire et de faire évoluer l’architecture de manière fiable, tout en réduisant les risques d’erreurs humaines.

Ainsi, ce projet illustre la rencontre entre quatre domaines clés : l’IA générative pour la compréhension et la reproduction du style visuel, le développement web pour l’accessibilité de l’outil, le cloud computing pour la performance et la scalabilité, et les pratiques DevOps pour l’automatisation et la fiabilité. Il répond à des besoins concrets de création, d’adaptation et d’optimisation de contenus visuels, dans un environnement professionnel globalisé et exigeant.


-------------------------------------------------------------------------------

[PROBLEMATIQUE]

Dans un environnement numérique en constante évolution, les images constituent l’un des supports de communication les plus puissants. Elles permettent de transmettre un message, un style et une identité visuelle de manière immédiate et universelle. Cependant, analyser et reproduire un visuel en conservant ses caractéristiques essentielles reste une tâche complexe, qui demande un œil artistique, du temps et une expertise technique.

Pour un créateur de contenu, cette étape peut représenter un frein important : il doit identifier manuellement les éléments stylistiques, les couleurs dominantes, la composition et l’ambiance générale afin de pouvoir réutiliser ou adapter le visuel à un autre contexte. Dans un cadre professionnel, par exemple, un graphiste indépendant travaillant pour les réseaux sociaux doit produire régulièrement des visuels cohérents et inspirants, tout en respectant des délais serrés.

De la même manière, une entreprise peut avoir besoin de s’inspirer d’un style existant pour lancer une campagne marketing. Prenons l’exemple d’une société chinoise souhaitant reproduire le style d’un poster ou d’une publicité étrangère pour l’adapter à son produit : sans outil automatisé, cela impliquerait un travail long et coûteux d’analyse manuelle, avec un risque de perdre certains détails subtils qui font la force visuelle de l’original.

Le problème central réside donc dans l’absence d’un outil capable de convertir automatiquement une image en description textuelle détaillée — un “prompt” — qui capture l’essence visuelle du contenu et qui soit directement exploitable pour la génération ou la reproduction d’images via l’intelligence artificielle.

Ce projet vise à combler ce manque, en proposant une solution automatisée, rapide et fiable, intégrant des technologies d’IA générative, de développement web, de déploiement cloud et de pipeline DevOps, afin de faciliter le travail des créateurs et des entreprises tout en réduisant les coûts et les délais.

[CLIENT]

Ce projet n’est pas réalisé pour un client précis dans le cadre d’un contrat professionnel, mais il est conçu pour répondre à un besoin réel identifié dans plusieurs secteurs liés à la création visuelle et au marketing numérique. L’objectif est de produire une solution qui puisse être utilisée aussi bien par des utilisateurs individuels que par des organisations ayant un besoin d’analyse et de reproduction de style visuel.



Type d’utilisateur

Créateurs de contenu (indépendants ou agences)
Entreprises cherchant à reproduire un style visuel
Formateurs et étudiants en design ou IA

Besoins principaux

Analyser un visuel existant et en extraire un prompt pour générer un visuel similaire appliqué à leur produit
Obtenir rapidement une description précise d’un visuel pour l’optimisation SEO, la création de contenu multilingue ou l’adaptation à différents contextes culturels

Exemple concret

Un créateur qui poste sur Instagram et souhaite adapter le style d’une affiche pour un public européen

Disposer d’un outil pédagogique pour comprendre les caractéristiques visuelles d’une image et s’exercer à la création assistée par IA

Une école de design utilisant l’outil pour illustrer la conversion image → texte dans un cours


L’application répond donc à des besoins transversaux :

Automatisation de l’analyse visuelle pour réduire le temps de travail.

Précision dans la description textuelle afin de capter les détails esthétiques.

Interopérabilité avec des générateurs d’images IA comme DALL·E, MidJourney ou Stable Diffusion, permettant d’exploiter directement les prompts générés.

Ce positionnement élargi permet au projet de viser à la fois un usage créatif (adaptation de styles, création artistique assistée) et un usage professionnel (marketing, communication visuelle, branding), tout en étant accessible à des utilisateurs non techniques grâce à une interface simple d’utilisation via API.

-------------------------------------------------------------------------------

Pour mener à bien ce projet, une méthodologie inspirée des pratiques DevOps et des principes Agile a été adoptée. L’objectif est de garantir un développement itératif, des livraisons fréquentes et un déploiement automatisé tout en assurant la qualité et la stabilité de l’application.


Approche générale

Découpage en phases courtes (sprints techniques) pour valider rapidement les fonctionnalités clés.

Automatisation maximale afin de réduire les interventions manuelles, limiter les erreurs et accélérer le déploiement.

Surveillance continue de l’application une fois déployée, avec remontée d’alertes en temps réel.


Principales étapes de réalisation

Conception de l’API
Développement d’une application Python (FastAPI ou Flask) capable de recevoir une image en entrée via un endpoint REST.
Intégration d’un modèle d’IA générative ou d’Azure Cognitive Services pour transformer l’image en description textuelle structurée.


Conteneurisation Docker
Création d’un Dockerfile multi-stage pour réduire la taille finale de l’image (< 200 MB).

Tests locaux pour s’assurer de la portabilité et de la stabilité de l’application.


Hébergement et infrastructure cloud
Stockage des images Docker dans Azure Container Registry (ACR) avec scan de sécurité activé.

Déploiement sur Azure Container Apps, permettant la mise à l’échelle automatique et un accès via un domaine public.

Gestion des secrets (clés API, credentials) via Azure Key Vault.


Mise en place du pipeline CI/CD

Utilisation de GitHub Actions pour automatiser :

Le build de l’image Docker.

Les tests unitaires.

Le push vers ACR.

Le déploiement en environnement staging.

La validation manuelle avant passage en production.


Monitoring et notifications
Configuration d’Azure Monitor et Log Analytics pour collecter les logs applicatifs, les métriques CPU/mémoire et détecter les erreurs.

Intégration d’un système de notifications via n8n ou Power Automate pour alerter l’équipe en cas d’échec de déploiement ou de problème de performance.

Infrastructure as Code (IaC)
Création de scripts Bicep ou Terraform pour déployer automatiquement l’ensemble de l’infrastructure Azure.

Versionnage des scripts dans GitHub pour assurer la traçabilité et permettre la reproduction sur d’autres environnements.


-------------------------------------------------------------------------------

Planification du projet

La réalisation du projet a été planifiée en six phases principales, chacune correspondant à un lot de livrables :
-------------------------------------------------------------------------------
Conclusion

Ce premier chapitre a permis de poser le cadre général du projet, en mettant en évidence la problématique à laquelle il répond, le public cible auquel il s’adresse et la démarche méthodologique adoptée pour sa réalisation. Nous avons vu que l’application vise à combler un manque concret dans le domaine de la création visuelle et du marketing, en automatisant la génération de descriptions textuelles précises à partir d’images grâce à l’intelligence artificielle.

En identifiant les besoins des créateurs de contenu, des entreprises et d’autres acteurs du secteur, nous avons défini des objectifs clairs et orientés vers l’efficacité, la rapidité et la précision. Sur le plan technique, la combinaison des technologies d’IA générative, de développement web, de cloud computing et de DevOps constitue un socle solide pour garantir la performance, la scalabilité et la fiabilité de la solution.

La méthodologie de travail, inspirée des pratiques agiles et DevOps, assure un cycle de développement itératif et automatisé, allant de la conception de l’API jusqu’au déploiement cloud et au monitoring en production. Cette approche permet de réduire les risques, d’optimiser les délais et de garantir une qualité constante à chaque étape.

Ainsi, ce chapitre introductif prépare le terrain pour les sections suivantes, qui détailleront plus en profondeur la conception, l’implémentation et la mise en œuvre technique de la solution proposée.



-------------------------------------------------------------------------------

{CHAPITRE 2}


[INTRODUCTION]

Ce deuxième chapitre a pour objectif de présenter les analyses préliminaires et fonctionnelles nécessaires à la conception de l’application. Avant de passer à la phase de réalisation, il est essentiel de disposer d’une vision claire et précise du projet, tant sur le plan conceptuel que technique. Cette étape permet non seulement de cadrer les fonctionnalités à développer, mais également de s’assurer que la solution proposée répond efficacement aux besoins identifiés dans le chapitre précédent.

Dans un premier temps, nous procéderons à une étude préliminaire afin de présenter de manière détaillée la finalité du projet, son champ d’application et les choix technologiques envisagés. Nous intégrerons également un état de l’art qui mettra en lumière les approches existantes et les solutions concurrentes, tout en analysant leurs limites pour mieux positionner notre outil sur le marché.

Ensuite, nous réaliserons une étude de l’existant visant à identifier les ressources déjà disponibles, les contraintes techniques et les éventuelles infrastructures réutilisables. Cette analyse permettra d’évaluer la valeur ajoutée de notre application par rapport aux solutions actuelles.

Nous passerons ensuite à l’étude fonctionnelle, qui constituera le cœur de ce chapitre. Cette partie définira de manière structurée :

Les besoins fonctionnels (ce que l’application doit faire).

Les besoins non fonctionnels (performances, sécurité, ergonomie, etc.).

Les acteurs qui interagiront avec le système et leurs rôles respectifs.

Enfin, un diagramme de cas d’utilisation global viendra illustrer visuellement la manière dont les différents acteurs interagissent avec l’application, facilitant ainsi la compréhension de l’architecture fonctionnelle.

Ce chapitre constitue donc une étape stratégique, garantissant que les bases du projet sont solides, cohérentes et orientées vers une mise en œuvre réussie dans les chapitres suivants.


-------------------------------------------------------------------------------

Le projet consiste à concevoir et développer une application web innovante capable de générer automatiquement des descriptions textuelles précises et complètes à partir d’images. L’outil exploite les avancées récentes de l’IA générative et des modèles de vision par ordinateur afin de reproduire ou de s’inspirer du style visuel d’une image donnée, tout en fournissant une description exploitable pour la création de nouveaux visuels.

Ce projet s’adresse principalement à deux types de cibles :

Les créateurs de contenu, qui souhaitent produire rapidement du texte descriptif fidèle à un visuel, afin de faciliter la création ou la déclinaison de designs.

Les entreprises internationales, comme une entreprise chinoise qui souhaiterait adapter le style d’un poster ou d’une publicité pour promouvoir ses propres produits, tout en conservant l’attrait visuel original.



L’application repose sur une architecture moderne et modulaire intégrant plusieurs volets techniques :

IA générative : utilisation de modèles avancés pour analyser le contenu visuel et en extraire une description riche en détails.

Développement web en Python : réalisation d’une interface intuitive et ergonomique pour permettre aux utilisateurs de téléverser des images et d’obtenir instantanément une description.

Cloud Computing : hébergement et exécution du projet sur une infrastructure cloud (Azure), garantissant scalabilité, disponibilité et facilité de maintenance.

DevOps : automatisation des processus de déploiement et de mise à jour grâce à des pipelines CI/CD et à l’intégration de conteneurs Docker.


L’objectif est de fournir une solution rapide, précise et évolutive, permettant à l’utilisateur de transformer une simple image en un texte exploitable pour la création de nouveaux contenus visuels. Cette approche ouvre de nombreuses possibilités, notamment dans les domaines du marketing digital, de la publicité, du e-commerce et de la création artistique.


Ce projet se distingue par sa capacité d’adaptation à différents contextes visuels et linguistiques, sa facilité d’utilisation grâce à une interface claire et intuitive et son infrastructure robuste capable de supporter une montée en charge et d’évoluer selon les besoins.

-------------------------------------------------------------------------------

État de l’art de l’activité de la ronde


Aujourd’hui, l’image occupe une place centrale dans la communication visuelle, que ce soit pour le marketing, la publicité ou la création de contenu artistique. Les entreprises comme les créateurs indépendants recherchent des solutions capables d’analyser un visuel, d’en extraire les caractéristiques principales, puis de les reproduire ou de les adapter à de nouveaux supports.

Différentes technologies sont déjà disponibles sur le marché. Les services de reconnaissance d’images proposés par des géants du cloud comme Microsoft Azure Computer Vision, Google Cloud Vision ou Amazon Rekognition permettent d’identifier rapidement les objets, les lieux ou les scènes présents dans une image. Cependant, ces solutions, bien qu’efficaces pour une analyse générale, produisent souvent des descriptions superficielles et peu adaptées à la reproduction fidèle d’un style artistique ou graphique.

Parallèlement, les avancées récentes en intelligence artificielle ont donné naissance à des modèles multimodaux tels que CLIP d’OpenAI, BLIP-2 ou encore Florence de Microsoft. Ces systèmes combinent compréhension visuelle et génération textuelle, offrant des descriptions plus précises et parfois capables de saisir l’esthétique globale d’une image. Néanmoins, leur intégration reste complexe et exige des ressources informatiques importantes, ce qui limite leur adoption par de petites structures ou des utilisateurs non techniques.

Les plateformes de création assistée par IA comme Canva Magic Studio, Adobe Firefly ou Figma AI se concentrent quant à elles sur la génération et la retouche de visuels à partir de texte. Bien qu’elles soient conviviales et rapides à utiliser, elles ne sont pas spécifiquement conçues pour analyser un visuel existant afin d’en extraire le style pour le reproduire fidèlement. De plus, elles fonctionnent souvent comme des environnements fermés, avec peu de possibilités de personnalisation du code ou des algorithmes.

C’est dans ce contexte que notre projet trouve sa place. L’objectif est de combiner la précision descriptive des modèles avancés avec la capacité de capturer l’essence graphique d’une image, afin de permettre sa reproduction et son adaptation à d’autres produits ou supports. La solution envisagée sera hébergée sur le cloud, dotée d’un pipeline DevOps pour assurer des mises à jour régulières et d’une interface intuitive, accessible aussi bien aux créateurs amateurs qu’aux professionnels. Elle se positionnera ainsi comme un outil polyvalent et innovant, capable de combler le fossé entre l’analyse visuelle et la création graphique.

-------------------------------------------------------------------------------

Étude de l’existant


Avant de concevoir notre propre solution, il est essentiel d’analyser l’existant afin de comprendre les forces et les limites des approches déjà présentes sur le marché. Cette étude permet d’identifier les références technologiques pertinentes et de mettre en évidence les manques auxquels notre projet pourra répondre.

Actuellement, plusieurs solutions proposent des fonctionnalités proches de notre objectif, mais aucune ne couvre l’intégralité du besoin ciblé. Les services de reconnaissance d’images, comme Google Cloud Vision, Microsoft Azure Cognitive Services ou Amazon Rekognition, se distinguent par leur capacité à analyser rapidement des visuels et à fournir des métadonnées structurées (objets détectés, couleurs dominantes, texte présent). Ces outils sont robustes, fiables et bien intégrés dans des écosystèmes cloud, mais leur orientation reste généraliste. Ils sont rarement optimisés pour capturer et reproduire le style graphique d’un visuel, un aspect essentiel pour notre projet.

Du côté de la génération et de l’édition d’images, des plateformes comme Adobe Firefly, Canva Magic Studio ou MidJourney permettent de créer des visuels originaux à partir de commandes textuelles. Elles offrent une grande flexibilité créative, mais elles se basent principalement sur la génération ex nihilo, sans véritable analyse approfondie d’images préexistantes. Les tentatives de « style transfer » dans ces outils restent souvent approximatives et difficiles à contrôler.

Par ailleurs, les modèles open source tels que Stable Diffusion ou BLIP-2 ouvrent la voie à des approches plus personnalisées. Ils permettent d’intégrer dans un même flux de travail la compréhension d’image, la description en langage naturel et la génération visuelle. Toutefois, leur mise en place nécessite des compétences avancées en IA et en déploiement d’infrastructures, ce qui constitue une barrière pour des entreprises non spécialisées.


Face à ce panorama, on observe donc deux grandes catégories de solutions :

Les outils spécialisés dans l’analyse d’images mais limités en reproduction stylistique.

Les outils axés sur la création graphique mais peu performants dans l’analyse fine et la réutilisation d’un style existant.


Notre projet se positionne comme un pont entre ces deux mondes. Il vise à offrir un système complet capable de :

Analyser un visuel de manière fine pour en extraire les éléments graphiques distinctifs.

Générer un contenu similaire ou adapté en conservant le style d’origine.

Proposer une interface simple, hébergée dans le cloud, avec une infrastructure DevOps permettant des mises à jour rapides et un déploiement continu.




Bonjour [Nom de l’encadrante],

Veuillez trouver ci-joint le livrable du rapport de stage, tel que convenu.
N’hésitez pas à me faire part de vos remarques ou suggestions afin que je puisse apporter les ajustements nécessaires.

Je reste bien entendu disponible pour toute clarification.

Cordialement,
Nassim Zahri










